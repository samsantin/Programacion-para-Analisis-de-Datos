{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samys\\AppData\\Local\\Temp\\ipykernel_28668\\1222050232.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_with_names = {\n",
    "    'ArcticMonkeys':'https://kworb.net/spotify/artist/7Ln80lUS6He07XvHI8qqHH_songs.html',\n",
    "    'BTS': 'https://kworb.net/spotify/artist/3Nrfpe0tUJi4K4DXYWgMUX_songs.html',\n",
    "    'Coldplay':'https://kworb.net/spotify/artist/4gzpq5DPGxSnKTe4SA8HAU_songs.html',\n",
    "    'ImagineDragons':'https://kworb.net/spotify/artist/53XhwfbYqKCa1cC15pYq2q_songs.html',\n",
    "    'LinkinPark':'https://kworb.net/spotify/artist/6XyY86QOPPrYVGvF9ch6wz_songs.html',\n",
    "    'Maroon5':'https://kworb.net/spotify/artist/04gDigrS5kc9YWfZHwBETP_songs.html',\n",
    "    'OneDirection': 'https://kworb.net/spotify/artist/4AK6F7OLvEQ5QYCBNiQWHq_songs.html',\n",
    "    'OneRepublic': 'https://kworb.net/spotify/artist/5Pwc4xIPtQLFEnJriah9YJ_songs.html',\n",
    "    'Queen': 'https://kworb.net/spotify/artist/1dfeR4HaWDbWqFHLkxsg1d_songs.html',\n",
    "    'RedHotChiliPeppers' : 'https://kworb.net/spotify/artist/0L8ExT028jH3ddEcZwqJJ5_songs.html',\n",
    "    'TheBeatles': 'https://kworb.net/spotify/artist/3WrFJ7ztbogyGnTHbHJFl2_songs.html',\n",
    "    'TheChainsmokers': 'https://kworb.net/spotify/artist/69GGBxA162lTqCwzJG5jLp_songs.html',\n",
    "    'TwentyOnePilots' : 'https://kworb.net/spotify/artist/3YQKmKGau1PzlVlkL1iodx_songs.html'\n",
    "}\n",
    "\n",
    "data_frames = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the website\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all tables on the page\n",
    "        tables = soup.find_all('table')\n",
    "\n",
    "        # Extract the first table with the song data\n",
    "        if len(tables) > 0:\n",
    "            song_table = tables[0]\n",
    "            song_rows = song_table.find_all('tr')\n",
    "\n",
    "            # Initialize lists to store song data\n",
    "            songs = []\n",
    "            total_streams = []\n",
    "            as_lead_streams = []\n",
    "            solo_streams = []\n",
    "            as_feature_streams = []\n",
    "\n",
    "            # Iterate over the song rows and extract data\n",
    "            for row in song_rows[1:]:  # Skipping the header row\n",
    "                columns = row.find_all('td')\n",
    "                songs.append(columns[0].text.strip())\n",
    "                total_streams.append(columns[1].text.strip())\n",
    "                as_lead_streams.append(columns[2].text.strip())\n",
    "                solo_streams.append(columns[3].text.strip())\n",
    "                as_feature_streams.append(columns[4].text.strip())\n",
    "\n",
    "            # Create a DataFrame for song data\n",
    "            song_data = {\n",
    "                'Song': songs,\n",
    "                'Total Streams': total_streams,\n",
    "                'As Lead Streams': as_lead_streams,\n",
    "                'Solo Streams': solo_streams,\n",
    "                'As Feature Streams': as_feature_streams\n",
    "            }\n",
    "            df_songs = pd.DataFrame(song_data)\n",
    "        else:\n",
    "            print(\"No song data found on the page\")\n",
    "            return None\n",
    "\n",
    "        # Extract the second table with the additional data\n",
    "        if len(tables) > 1:\n",
    "            additional_table = tables[1]\n",
    "            additional_rows = additional_table.find_all('tr')\n",
    "\n",
    "            # Initialize lists to store additional data\n",
    "            song_titles = []\n",
    "            streams = []\n",
    "            daily = []\n",
    "\n",
    "            # Iterate over the additional rows and extract data\n",
    "            for row in additional_rows[1:]:  # Skipping the header row\n",
    "                columns = row.find_all('td')\n",
    "                song_titles.append(columns[0].text.strip())\n",
    "                streams.append(columns[1].text.strip())\n",
    "                if len(columns) > 2:\n",
    "                    daily.append(columns[2].text.strip())\n",
    "                else:\n",
    "                    daily.append('')  # Appending empty string if daily gain is not available\n",
    "\n",
    "            # Create a DataFrame for additional data\n",
    "            additional_data = {\n",
    "                'Song Title': song_titles,\n",
    "                'Streams': streams,\n",
    "                'Daily': daily\n",
    "            }\n",
    "            df_additional = pd.DataFrame(additional_data)\n",
    "        else:\n",
    "            print(\"No additional data found on the page\")\n",
    "            return None\n",
    "\n",
    "        return df_songs, df_additional\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to retrieve the website\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for ArcticMonkeys...\n",
      "Scraping data for BTS...\n",
      "Scraping data for Coldplay...\n",
      "Scraping data for ImagineDragons...\n",
      "Scraping data for LinkinPark...\n",
      "Scraping data for Maroon5...\n",
      "Scraping data for OneDirection...\n",
      "Scraping data for OneRepublic...\n",
      "Scraping data for Queen...\n",
      "Scraping data for RedHotChiliPeppers...\n",
      "Scraping data for TheBeatles...\n",
      "Scraping data for TheChainsmokers...\n",
      "Scraping data for TwentyOnePilots...\n"
     ]
    }
   ],
   "source": [
    "for name, url in urls_with_names.items():\n",
    "    print(f\"Scraping data for {name}...\")\n",
    "    df_songs, df_additional = scrape_data(url)\n",
    "    data_frames[name] = {'songs': df_songs, 'additional': df_additional}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data for BTS:\n",
      "Artist Info:\n",
      "      Song   Total Streams As Lead Streams    Solo Streams As Feature Streams\n",
      "0  Streams  38,001,558,151  33,896,000,146  30,717,337,774      4,105,558,005\n",
      "1    Daily      13,646,366      11,675,980      10,879,067          1,970,386\n",
      "2   Tracks             272             249             232                 23\n",
      "\n",
      "Song Data:\n",
      "                                            Song Title        Streams    Daily\n",
      "0                                             Dynamite  1,808,091,577  586,403\n",
      "1                                               Butter  1,219,205,644  333,709\n",
      "2                                        * My Universe  1,205,927,133  629,453\n",
      "3                          Boy With Luv (Feat. Halsey)  1,129,232,727  296,553\n",
      "4            * Left and Right (Feat. Jung Kook of BTS)    886,381,679  579,799\n",
      "..                                                 ...            ...      ...\n",
      "267                        Let Me Know - Japanese Ver.      2,275,228      678\n",
      "268  * Bad Decisions (with BTS & Snoop Dogg) - Inst...      1,867,531      383\n",
      "269                  Shingeki no Boudan - Sonpub Remix      1,813,370    1,755\n",
      "270                       Just One Day - Japanese Ver.      1,798,415      635\n",
      "271                               IDOL - Stadium Remix        404,358       83\n",
      "\n",
      "[272 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def print_website_data(data_frames, website_name):\n",
    "    if website_name in data_frames:\n",
    "        dfs = data_frames[website_name]\n",
    "        print(f\"\\nData for {website_name}:\")\n",
    "        print(\"Artist Info:\")\n",
    "        print(dfs['songs'])\n",
    "        print(\"\\nSong Data:\")\n",
    "        print(dfs['additional'])\n",
    "    else:\n",
    "        print(f\"Website '{website_name}' not found in the data frames.\")\n",
    "\n",
    "print_website_data(data_frames, 'BTS')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
